---

- name: apt install
  apt: pkg={{ item }} update_cache=yes cache_valid_time=3600
  with_items:
    - git
    - uuid-runtime
    - rsync
    - daemontools # supervise
  sudo_user: root

########################################################################
#                    INSTALL GITHUB KEY AND CHECKOUT                   #
########################################################################

- name: mkdir ~/.ssh
  file: path={{ home }}/.ssh state=directory
- name: check for the piloteur-devices id_rsa
  stat: path={{ home }}/.ssh/id_rsa
  register: p
- name: upload the piloteur-devices id_rsa
  copy: src=piloteur-devices dest={{ home }}/.ssh/id_rsa mode=600
  when: p.stat.isreg is not defined or p.stat.isreg == false

- name: cache the github.com host key
  shell: creates="{{ home }}/.ssh/.cached-host-key-github.com"
      ssh-keyscan -t ecdsa,rsa,dsa github.com >> ~/.ssh/known_hosts;
      touch {{ home }}/.ssh/.cached-host-key-github.com

- name: checkout the code repo
  git: dest={{ code }} repo={{ code_repo }} depth=1 version={{ code_rev }}
- name: checkout the blobs repo
  git: dest={{ blobs }} repo={{ blobs_repo }} depth=1 version={{ blobs_rev }}


########################################################################
#           GENERATE/GET/INSTALL THE NODE-ID AND THE CLASSES           #
########################################################################

- name: generate node unique UUID if not existing
  shell: creates={{ home }}/.node-id
      uuidgen > {{ home }}/.node-id
  when: user_node_id is not defined

- name: check the user_node_id/1
  shell: executable=/bin/bash [[ {{ user_node_id }} =~ ^[a-z0-9-]+$ ]]
  when: user_node_id is defined
  register: result
  ignore_errors: True
- name: check the user_node_id/2
  fail: msg="invalid characters in the user_node_id"
  when: result|failed

- name: install the user_node_id
  copy: content={{ user_node_id }} dest={{ home }}/.node-id
  when: user_node_id is defined

# - name: get the node unique UUID
#   command: "cat {{ home }}/.node-id"
#   register: node_id
# - debug: >
#     msg="node-id: {{ node_id.stdout }}"

- name: ensure .node-classes exists
  file: path={{ home }}/.node-classes state=touch
- name: install the node classes
  copy: content={{ node_classes }} dest={{ home }}/.node-classes
  when: node_classes is defined

- local_action: command gen_token.py "{{ node_id }},{{ node_classes }}"
  register: config_token
  when: user_node_id is defined and node_classes is defined
- name: install the config token
  copy: content={{ config_token.stdout.strip() }} dest={{ home }}/.config-token
  when: user_node_id is defined and node_classes is defined


########################################################################
#                    DEPENDENCIES INSTALLATION                         #
########################################################################

## (apt moved to the top)

- name: get the pip installer
  get_url: url=https://raw.github.com/pypa/pip/master/contrib/get-pip.py
      dest={{ home }}/get-pip.py owner=root group=root mode=0755
  sudo_user: root
- name: install pip
  command: python {{ home }}/get-pip.py
      creates=/usr/local/bin/pip
  sudo_user: root
- name: install virtualenv
  pip: name=virtualenv version=1.11.4
      extra_args="--no-index --use-wheel --find-links={{ blobs }}/wheelhouse"
  sudo_user: root

- name: install the google-dns tool
  copy: src=google-dns dest=/usr/local/bin/google-dns
      owner=root group=root mode=0755
  sudo_user: root

- name: install usbreset /1
  command: cp {{ blobs }}/usbreset-{{ ansible_machine }} /usr/local/bin/usbreset
      creates=/usr/local/bin/usbreset
  # Note: this will not update usbreset if changed
  sudo_user: root
- name: install usbreset /2
  file: path=/usr/local/bin/usbreset owner=root group=root mode=0755
  sudo_user: root

- name: create the virtualenv and install requirements.txt
  pip: virtualenv={{ home }}/ENV/ requirements={{ endpoint }}/requirements.txt
      extra_args="--no-index --use-wheel --find-links={{ blobs }}/wheelhouse"

- name: run config_pull
  command: {{ endpoint }}/pull_config.py "{{ config_node_addr }}"
  when: config_node_addr is defined
  # TODO
- name: create config_pull cron entry
  cron: name="config_pull"
      job="{{ endpoint }}/pull_config.py '{{ config_node_addr }}'"
  when: config_node_addr is defined
  # TODO


########################################################################
#                                IMPORTS                               #
########################################################################

- include: armv6l.yml
  when: ansible_machine=="armv6l"
- include: x86_64.yml
  when: ansible_machine=="x86_64"

# Run upgrade migrations tasks
- include: upgrade.yml

- include: drivers.yml


########################################################################
#                                BRIDGE                                #
########################################################################

- name: extract bridge host
  shell: "jq --raw-output .ssh_bridge_host < {{ home }}/config.json"
  register: ssh_bridge_host
- name: cache the remote host key
  shell: creates="{{ home }}/.ssh/.cached-host-key-{{ ssh_bridge_host.stdout.strip() }}"
      ssh-keyscan -t ecdsa,rsa,dsa {{ ssh_bridge_host.stdout.strip() }} >> ~/.ssh/known_hosts;
      touch {{ home }}/.ssh/.cached-host-key-{{ ssh_bridge_host.stdout.strip() }}

- name: install the bridge init script
  template: src=bridge dest=/etc/init.d/bridge
      owner=root group=root mode=0755
  sudo_user: root
- name: enable bridge
  service: name=bridge enabled=yes state=started
  sudo_user: root

- name: install the ssh config
  copy: src=ssh_config dest={{ home }}/.ssh/config

########################################################################
#                                 MISC                                 #
########################################################################

- name: disable rsyslogd
  service: name=rsyslog state=stopped enabled=no
  sudo_user: root

# Cache the sync_nodes SSH host key
- name: extract remote host
  shell: "jq --raw-output '.sync_nodes|.[].host' < {{ home }}/config.json"
  register: sync_nodes
- name: cache the remote host key
  shell: creates="{{ home }}/.ssh/.cached-host-key-{{ item.strip() }}"
      ssh-keyscan -t ecdsa,rsa,dsa {{ item.strip() }} >> ~/.ssh/known_hosts;
      touch {{ home }}/.ssh/.cached-host-key-{{ item.strip() }}
  with_items: sync_nodes.stdout_lines

# Create folders
- name: extract the folders that have to be created
  shell: >
      jq --raw-output '[.logs_path+(.logging_modules|.[]), .logs_path+(.loaded_drivers|.[])+"-driver", .logs_path, .data_path]|.[]' < {{ home }}/config.json
  register: folders
- name: mkdir
  file: path={{ item }} state=directory
  with_items: folders.stdout_lines

# Upload a script to ensure that the folders exist on boot
- name: upload /etc/init.d/mkdirs
  template: src=mkdirs dest=/etc/init.d/mkdirs
      owner=root group=root mode=0755
  sudo_user: root
- name: enable /etc/init.d/mkdirs
  service: name=mkdirs enabled=yes
  sudo_user: root

# Setup sudoers file
- name: setup sudo
  template: src=sudoers dest=/etc/sudoers.d/piloteur validate='visudo -cf %s'
      owner=root group=root
  sudo_user: root

# Setup cronjobs
- name: create cron entries
  cron: name="run '{{ item }}'"
      job=". /etc/profile; . $HOME/.profile; cd '{{ endpoint }}'; '{{ endpoint }}/{{ item }}'"
  with_items:
    - runner.sh
    - watchdog.sh
